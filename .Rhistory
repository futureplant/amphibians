# Load reference map (timeslice)
num <- as.numeric(difftime(pred_times[i], start_time, units="mins"))
load(paste0("slice2019_", sprintf("%03d", num), ".Rdata"))
# Is threshold exceeded in reference map?
timeslice$danger <- timeslice$plume > 100
# compute misclassification cost
mycost <- mycost + sum(ifelse(mymap$danger == F & timeslice$danger == T, 5,
ifelse(mymap$danger == T & timeslice$danger == F, 1, 0)))
}
mycost
CreateSnapshot <- function(mapdata, predtime, starttime, grd){
mapdata$t <- as.numeric(difftime(predtime, mapdata$datime, units="mins"))
grd$t <- rep(as.numeric(difftime(predtime, starttime, units="mins")),10000)
# max age to be considered: 25 mins
subdata <- subset(mapdata, t>=0 & t <= 5)
subdata$t <- subdata$t*5.0  # anisotropy time dimension
if (nrow(subdata) > 0){
coordinates(subdata) <- ~x+y+t
outmap <- idw(ppm~1, subdata, SpatialPoints(grd), idp=2.0, debug.level=0)$var1.pred
} else{
outmap <- rep(0, 10000)
}
outmap <-  SpatialPixelsDataFrame(SpatialPoints(grd[1:2]), data.frame(ppm=outmap))
# where/when is the threshold exceeded?
outmap$danger <- outmap$ppm > 100
return(outmap)
}
# Create maps, compute misclassification costs.
mycost <- 0
for (i in 1:9){
mymap <- CreateSnapshot(all_rd, pred_times[i], start_time, RDgrid)
# Load reference map (timeslice)
num <- as.numeric(difftime(pred_times[i], start_time, units="mins"))
load(paste0("slice2019_", sprintf("%03d", num), ".Rdata"))
# Is threshold exceeded in reference map?
timeslice$danger <- timeslice$plume > 100
# compute misclassification cost
mycost <- mycost + sum(ifelse(mymap$danger == F & timeslice$danger == T, 5,
ifelse(mymap$danger == T & timeslice$danger == F, 1, 0)))
}
mycost
# Clean workspace
rm(list=ls())
# Load required packages
library(sp)
library(gstat)
library(rgdal)
library(rgeos)
setwd("D:/Toxicplume")  # set to proper folder
# **************************
# ------- Question 2 -------
# **************************
# Enter group number
group <- 4   # provide correct number
# download "truths" to local folder, to speed up things later
for (i in 0:90){
fname = paste0("slice2019_", sprintf("%03d", i), ".Rdata")
#download.file(paste0("http://scomp5062.wur.nl/courses/grs33306/input/", fname), fname)
con <- url(paste0("http://scomp5062.wur.nl/courses/grs33306/input/", fname))
load(con)
close(con)
rm(con)
save(timeslice, file=fname)
}
rm(timeslice)
# Read the data of all groups
# IT MAY BE NECESSARY TO CLEAR THE CACHE OF YOUR WEB BROWSER
# (F5 or Ctrl-Shift-R while using the web browser)
all_obs <- read.table(url("http://scomp5062.wur.nl/courses/grs33306/output/observations.txt"), header=T)
all_obs$datime <- as.POSIXct(all_obs$datime, format='%Y-%m-%d %H:%M:%S')
# delete NA ppm records, if any
delme <- which(is.na(all_obs$ppm))
if(length(delme) > 0)
all_obs <- all_obs[-delme,]
# Delete accidental adjacent duplicate records with identical co-ordinates
# and up to 5 seconds temporal difference.
for (i in nrow(all_obs):2)
if (all_obs$GNo[i]==all_obs$GNo[(i-1)] && all_obs$lon[i]==all_obs$lon[(i-1)]
&& all_obs$lat[i]==all_obs$lat[(i-1)])
if (as.numeric(difftime(all_obs$datime[i], all_obs$datime[(i-1)],
units="secs")) <= 5)
all_obs <- all_obs[-i,]
# Set time boundaries & select observations within time frame
end_time <- as.POSIXct("2019-02-28 15:35:00", format='%Y-%m-%d %H:%M:%S')
start_time <- as.POSIXct("2019-02-28 14:00:00", format='%Y-%m-%d %H:%M:%S')
all_obs <- subset(all_obs, datime >= start_time & datime <= end_time)
# Prediction times (9 snapshots, 10 minutes apart, starting 14:10)
pred_times <- start_time + 1:9*as.difftime(10,  units="mins")
# Make spatial & assign World Geodetic System (WGS84) coordinate system
coordinates(all_obs) <- ~lon+lat
all_obs@proj4string <- CRS("+proj=longlat +datum=WGS84")
# Project to Dutch (RD) grid (Note: this is an approximate transformation).
prj_string_RD <- CRS("+proj=sterea +lat_0=52.15616055555555 +lon_0=5.38763888888889
+k=0.9999079 +x_0=155000 +y_0=463000 +ellps=bessel +towgs84=565.2369,50.0087,465.658,
-0.406857330322398,0.350732676542563,-1.8703473836068,4.0812 +units=m +no_defs")
all_rd <- spTransform(all_obs, prj_string_RD)
dimnames(all_rd@coords)[[2]] <- c("x", "y")
# Retrieve extent study area from the server
con <- url("http://scomp5062.wur.nl/courses/grs33306/input/extents.Rdata")
load(con)
close(con)
rm(con)
# Define 2D prediction grid in RD coordinates, later time will be added
RDgrid <- expand.grid(x=seq(RD_minX, RD_maxX, length.out=100),
y=seq(RD_minY, RD_maxY, length.out=100))
# Coerce spatial data to plain data frame
all_rd <- as.data.frame(all_rd)
setwd("D:/GIS Files/amphiR/amphibians")
waterpoints <- read_sf(dsn = "./data/waterpoints", layer = "SHAPEFILE")
# This file will provide the points to turn into markers
# Starting with dummy points
library(sf)
install.packages(sf)
install.packages('sf')
waterpoints <- read_sf(dsn = "./data/waterpoints", layer = "SHAPEFILE")
# This file will provide the points to turn into markers
# Starting with dummy points
library(sf)
waterpoints <- read_sf(dsn = "./data/waterpoints", layer = "SHAPEFILE")
waterpoints <- read_sf(dsn = "./data/waterpoints.shp", layer = "SHAPEFILE")
setwd("D:/GIS Files/amphiR/amphibians/scripts")
waterpoints <- read_sf(dsn = "waterpoints.shp", layer = "SHAPEFILE")
waterpoints <- read_sf(dsn = "./waterpoints.shp", layer = "SHAPEFILE")
waterpoints <- read_sf(dsn = ".", layer = "SHAPEFILE")
waterpoints <- read_sf(dsn = ".", layer = "SHAPEFILE")
waterpoints <- read_sf(dsn = "waterpoints", layer = "SHAPEFILE")
waterpoints <- read_sf(dsn = "waterpoints.shp", layer = "SHAPEFILE")
waterpoints <- read_sf(dsn = "waterpoints.shp", layer = "SHAPEFILE")
waterpoints <- read_sf(dsn = "D:\GIS Files\amphiR\amphibians\scripts\waterpoints.shp", layer = "SHAPEFILE")
waterpoints <- read_sf(dsn = "scripts\waterpoints.shp", layer = "SHAPEFILE")
waterpoints <- read_sf(dsn = "scripts/waterpoints.shp", layer = "SHAPEFILE")
file.exists("waterpoints.shp")
waterpoints <- read_sf(dsn = "waterpoints.shp", layer = "SHAPEFILE")
st_read("waterpoints.shp")
setwd("D:/GIS Files/amphiR/amphibians")
st_read("data/waterpoints.shp")
waterpoints <- st_read("data/waterpoints.shp")
waterpoints
shiny::runApp()
install.packages('shinydashboard')
runApp()
runApp()
waterpoints
waterponts$geometry
waterpoints$geometry
waterpoints$geometry[1]
waterpoints$geometry[[1]]
st_coordinates(waterpoints)
st_coordinates(waterpoints[1])
st_coordinates(waterpoints[1,1])
st_coordinates(waterpoints$X)
st_coordinates(waterpoints$x)
st_coordinates(waterpoints)
class(st_coordinates(waterpoints))
coords <- st_coordinates(waterpoints)
coords['X']
coords['X',]
coords[,'X']
runApp()
runApp()
waterpoints
waterpoints$OBJECTID
runApp()
setwd("D:/GIS Files/amphiR/amphibians")
shiny::runApp()
shiny::runApp()
runApp()
?clusteroptions
?markerClusterOptions
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
instal..packages('gsheet')
install.packages('gsheet')
library(gsheet)
?ghseet
?gsheet2tbl
read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
url <- https://docs.google.com/spreadsheets/d/1rHUTv2m6N1cmx4gP0zwKxRBQok9Zr-FEBmf90Ksp7eU/edit?usp=sharing
url <- 'https://docs.google.com/spreadsheets/d/1rHUTv2m6N1cmx4gP0zwKxRBQok9Zr-FEBmf90Ksp7eU'
read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
class(read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE))
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
dtf$El.punt.d.aigua.és.adequat.
dtf[which.min(dtf$El.punt.d.aigua.és.adequat.),"No (piscina, ciment, edifici...)"]
dtf[which.min(dtf$El.punt.d.aigua.és.adequat.),'No (piscina, ciment, edifici...)']
dtf[which(dtf$El.punt.d.aigua.és.adequat.),'No (piscina, ciment, edifici...)']
?which
dtf[which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)']
which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)'
which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)'
which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)')
dtf[which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)')]
dtf[which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)'),2]
url <- 'https://docs.google.com/spreadsheets/d/1rHUTv2m6N1cmx4gP0zwKxRBQok9Zr-FEBmf90Ksp7eU'
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
dtf$El.punt.d.aigua.és.adequat.
dtf[which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)'),2]
url <- 'https://docs.google.com/spreadsheets/d/1rHUTv2m6N1cmx4gP0zwKxRBQok9Zr-FEBmf90Ksp7eU'
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
dtf$El.punt.d.aigua.és.adequat.
dtf[which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)'),2]
url <- 'https://docs.google.com/spreadsheets/d/1rHUTv2m6N1cmx4gP0zwKxRBQok9Zr-FEBmf90Ksp7eU'
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
dtf$El.punt.d.aigua.és.adequat.
dtf[which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)'),2]
library(gsheet)
url <- 'https://docs.google.com/spreadsheets/d/1rHUTv2m6N1cmx4gP0zwKxRBQok9Zr-FEBmf90Ksp7eU'
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
dtf$El.punt.d.aigua.és.adequat.
dtf[which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)'),2]
runApp()
url <- 'https://docs.google.com/spreadsheets/d/1rHUTv2m6N1cmx4gP0zwKxRBQok9Zr-FEBmf90Ksp7eU'
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
dtf$El.punt.d.aigua.és.adequat.
dtf[which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)'),2]
?addMarkers
runApp()
?awesomeIcons
runApp()
samples <- getGsheet()
source("scripts/readgsheets.R")
samples <- getGsheet()
runApp()
runApp()
runApp()
samples <- getGsheet()
?sapply
waterpoints <- getPoints()
waterpoints <- getPoints()
samples <- getGsheet()
class(samples)
samples
samples <- getGsheet()
waterpoints <- getPoints()
class(samples)
samples
samples <- getGsheet()
samples
# url of gsheet which contains form answers
url <- 'https://docs.google.com/spreadsheets/d/1rHUTv2m6N1cmx4gP0zwKxRBQok9Zr-FEBmf90Ksp7eU'
# creates dataframe from google sheet answers
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
dtf[which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)'),2]
# returns point ID's of points that have been classified as not suitable
return(dtf[which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)'),2])
samples <- getGsheet()
waterpoints <- getPoints()
samples
source("scripts/readgsheets.R")
samples <- getGsheet()
samples
class(samples)
getColor <- function(samples,waterpoints) {
sapply(waterpoints, function(waterpoints) {
if(waterpoints$OBJECTID %in% samples) {
"red"
} else {
"blue"
} })
}
?addMarkers
?addAwesomeMarkers
runApp()
is.atomic(samples)
waterpoints
waterpoints$OBJECTID
getColor <- function(samples,waterpoints) {
sapply(waterpoints, function(waterpoints) {
if(waterpoints$OBJECTID %in% samples) {
"red"
} else {
"blue"
} })
}
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
print(waterpoint$OBJECTID)
print(waterpoints$OBJECTID)
sapply(waterpoints,print(waterpoints$OBJECTID))
sapply(waterpoints,print(waterpoints$OBJECTID))
runApp()
runApp()
runApp()
getColor(samples,waterpoints)
getColor <- function(samples,waterpoints) {
sapply(waterpoints, function(waterpoints) {
if(waterpoints["OBJECTID"] %in% samples) {
"blue"
} else {
"blue"
}
})
}
getColor(samples,waterpoints)
waterpoints <- getPoints()
getColor(samples,waterpoints)
samples <- getGsheet()
getColor(samples,waterpoints)
runApp()
getColor(samples,waterpoints)
class(getColor(samples,waterpoints))
runApp()
runApp()
runApp()
runApp()
sapply(waterpoints$OBJECTID, function(OBJECTID,samples) {
if(OBJECTID > 100) {
"blue"
} else {
"red"
}
})
runApp()
samples
runApp()
samples
waterpoints
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?sapply
runApp()
runApp()
runApp()
runApp()
runApp()
library(raster)
ndvi=raster('pr_b02_NDVI1.tif')
snor=raster('pr_b03_DeltaS1.tif')
sslo=raster('pr_b03_DeltaS_SlopeCure1.tif')
ndvi <- resample(ndvi,snor)
sslo <- resample(sslo,snor)
ext <- extent(sslo)
ndvi <- crop(ndvi,ext)
sslo <- crop(sslo,ext)
normalstack <- stack(c(ndvi,snor))
slopedstack <- stack(c(ndvi,sslo))
jnk=layerStats(normalstack, 'pearson', na.rm=T)
corr_matrix=jnk$'pearson correlation coefficient'
lmk=layerStats(slopedstack, 'pearson', na.rm=T)
ndvi=raster('pr_b02_NDVI1.tif')
setwd("D:/GIS Files/waterstorage/Tiffjes")
ndvi=raster('pr_b02_NDVI1.tif')
snor=raster('pr_b03_DeltaS1.tif')
sslo=raster('pr_b03_DeltaS_SlopeCure1.tif')
ndvi <- resample(ndvi,snor)
sslo <- resample(sslo,snor)
corr(ndvi,sslo)
?corr
cor(ndvi,sslo)
cor(c(ndvi,sslo))
runApp('D:/GIS Files/amphiR/amphibians')
class(waterpoints)
waterpoints <- getPoints()
setwd("D:/GIS Files/amphiR/amphibians")
waterpoints <- getPoints()
class(waterpoints)
samples <- getGsheet()
samples
head(waterpoints)
head(waterpoints[1,])
head(waterpoints[,1])
head(waterpoints)
waterpoints = waterpoints[waterpoints$OBJECTID %in% samples,]
runApp()
runApp()
runApp()
vectorofvectors <- c(C(1,1),c(2,3))
vectorofvectors <- c(C(1,2),c(2,3))
runApp()
runApp()
runApp()
runApp()
dtf
# url of gsheet which contains form answers
url <- 'https://docs.google.com/spreadsheets/d/1rHUTv2m6N1cmx4gP0zwKxRBQok9Zr-FEBmf90Ksp7eU'
# creates dataframe from google sheet answers
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
runApp()
dtf[which(dtf$Visita.finalitzada != 'Si')]
dtf[which(dtf$Visita.finalitzada != 'Si'& length(dtf$Visita.finalitzada)>0)]
dtf[which(dtf$Visita.finalitzada != 'Si'& length(dtf$Visita.finalitzada)>1)]
dtf[which(dtf$Visita.finalitzada != 'Si'& dtf$Visita.finalitzada>1)]
dtf[which(dtf$Visita.finalitzada != 'Si'& length(dtf$Visita.finalitzada>1)]
dtf[which(dtf$Visita.finalitzada != 'Si'& length(dtf$Visita.finalitzada>1))]
dtf[which(length(dtf$Visita.finalitzada>1))]
dtf[which(dtf$Visita.finalitzada != 'Si'& dtf$Visita.finalitzada == "We still need to do the thing")]
# creates dataframe from google sheet answers
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
dtf[which(dtf$Visita.finalitzada != 'Si'& dtf$Visita.finalitzada == "We still need to do the thing")]
dtf[which(dtf$Visita.finalitzada != 'Si'& dtf$Visita.finalitzada == "We still need to do the thing")]
dtf
dtf[which(dtf$Visita.finalitzada != 'Si'& dtf$Visita.finalitzada == "We still need to do the thing")]
# creates dataframe from google sheet answers
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
dtf[which(dtf$Visita.finalitzada != 'Si'& dtf$Visita.finalitzada == "No")]
dtf
runApp()
# creates dataframe from google sheet answers
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
dtf[which(dtf$Visita.finalitzada != 'Si'& dtf$Visita.finalitzada == "No")]
dtf[which(dtf$Visita.finalitzada == "No")]
# creates dataframe from google sheet answers
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
dtf[which(dtf$Visita.finalitzada == "No")]
dtf[which(dtf$Visita.finalitzada == "No"),]
dtf[which(dtf$Visita.finalitzada == "No"),2]
runApp()
runApp()
# url of gsheet which contains form answers
url <- 'https://docs.google.com/spreadsheets/d/1rHUTv2m6N1cmx4gP0zwKxRBQok9Zr-FEBmf90Ksp7eU'
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
(dtf[which(dtf$Visita.finalitzada == "No"),2])
# url of gsheet which contains form answers
url <- 'https://docs.google.com/spreadsheets/d/1rHUTv2m6N1cmx4gP0zwKxRBQok9Zr-FEBmf90Ksp7eU'
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
yes <- (dtf[which(dtf$Visita.finalitzada == "Si"),2])
yes
nos <- (dtf[which(dtf$Visita.finalitzada == "No"),2])
nos
?diff
?setdiff
setdiff(yes,nos)
setdiff(nos,yes)
vec1 <- c(1,2,3,4,5,6)
vec2 <- c(6,7,8,9)
setdiff(vec1,vec2)
sediff(vec2,vec1)
setdiff(vec2,vec1)
class(setdiff(vec2,vec1))
runApp()
runApp()
return((dtf[which(dtf$Visita.finalitzada == "Si"),2]))
(dtf[which(dtf$Visita.finalitzada == "Si"),2])
completes <- getCompletes(dtf)
source("scripts/readgsheets.R")
completes <- getCompletes(dtf)
completes
runApp()
?if
)
runApp()
runApp()
dtf[which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)'),2]
dtf[which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)'),2]
read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE)
?read.csv()
runApp()
read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE,fileEncoding = "UTF-8")
read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE,encoding = "UTF-8")
read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE,fileEncoding = "UTF-8",encoding = "UTF-8")
?gsheet2text
which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)
)
)
)
34
3e
3
43
43
4q()
return(dtf[which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)'),2])
dtf[which(dtf$El.punt.d.aigua.és.adequat. == 'No (piscina, ciment, edifici...)'),2]
read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE,fileEncoding = "UTF-8",encoding = "UTF-8")
source("scripts/readgsheets.R",encoding="utf-8")
source("scripts/readgsheets.R")
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE,fileEncoding = "UTF-8",encoding = "UTF-8")
?source()
source("scripts/readgsheets.R",encoding = "utf-8")
source("scripts/readgsheets.R",encoding = "UTF-8")
source("scripts/readgsheets.R",encoding = "Latin1")
runApp()
runApp()
dtf <- read.csv(text=gsheet2text(url, format='csv'), stringsAsFactors=FALSE,fileEncoding = "UTF-8",encoding = "UTF-8")
dtf[which(dtf$Accessibilitat == 'Sense accés'),2]
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
